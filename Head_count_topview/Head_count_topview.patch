--- src/head_count_topview.cpp
+++ src/head_count_topview.cpp
@@ -38,7 +38,6 @@
 #include <linux/input.h>
 #include <builtin_fp16.h>
 #include <opencv2/opencv.hpp>
-#include "wayland.h"
 
 
 using namespace std;
@@ -49,13 +48,9 @@
 
 /*Global Variables*/
 static float drpai_output_buf[INF_OUT_SIZE];
-static Wayland wayland;
 static pthread_t ai_inf_thread;
 static pthread_t kbhit_thread;
 static sem_t terminate_req_sem;
-
-static atomic<uint8_t> hdmi_obj_ready   (0);
-
 static uint32_t disp_time = 0;
 static int32_t drpai_freq;
 
@@ -67,12 +62,8 @@
 uint64_t drpaimem_addr_start = 0;
 bool runtime_status = false; 
 static vector<detection> det;
-
 float fps = 0;
-float TOTAL_TIME = 0;
-float INF_TIME= 0;
-float POST_PROC_TIME = 0;
-float PRE_PROC_TIME = 0;
+
 int32_t HEAD_COUNT= 0;
 int fd;
 
@@ -84,8 +75,9 @@
 cv::Mat output_image;
 
 /* Map to store input source list */
-std::map<std::string, int> input_source_map ={    
-    {"USB", 1}
+std::map<std::string, int> input_source_map ={
+    {"IMAGE", 1},    
+    {"USB", 2}
      } ;
 
 
@@ -335,8 +327,6 @@
     string str = "";
     string result_str;
     int32_t result_cnt =0;
-    uint32_t x = HEAD_COUNT_STR_X;
-    uint32_t y = HEAD_COUNT_STR_X;
     /* Draw bounding box on RGB image. */
     int32_t i = 0;
     for (i = 0; i < det.size(); i++)
@@ -385,6 +375,10 @@
         Point textleft(x_min,y_min+CLASS_LABEL_HEIGHT);
         Point textright(x_min+CLASS_LABEL_WIDTH,y_min);
 
+
+        std::cout<<"topleft :"<<topLeft<<endl;
+        std::cout<<"bottomRight :"<<bottomRight<<endl;
+
         rectangle(g_frame, topLeft, bottomRight, Scalar(0, 0, 0), BOX_THICKNESS);
         rectangle(g_frame, topLeft2, bottomRight2, Scalar(255, 255, 255), BOX_THICKNESS);
         /*solid rectangle over class name */
@@ -410,8 +404,6 @@
 
     Size size(MODEL_IN_H, MODEL_IN_W);
 
-    /* Preprocess time start */
-    auto t0 = std::chrono::high_resolution_clock::now();
     /*resize the image to the model input size*/
     resize(g_frame, frame1, size);
 
@@ -437,21 +429,9 @@
     Mat frame = frameCHW;
     int ret = 0;
 
-    /* Preprocess time ends*/
-    auto t1 = std::chrono::high_resolution_clock::now();
-
     /*start inference using drp runtime*/
     runtime.SetInput(0, frame.ptr<float>());
-
-    /* Inference time start */
-    auto t2 = std::chrono::high_resolution_clock::now();
     runtime.Run(drpai_freq);
-    /* Inference time end */
-    auto t3 = std::chrono::high_resolution_clock::now();
-    auto inf_duration = std::chrono::duration_cast<std::chrono::microseconds>(t3 - t2).count();
-
-    /* Postprocess time start */
-    auto t4 = std::chrono::high_resolution_clock::now();
 
     /*load inference out on drpai_out_buffer*/
     int32_t i = 0;
@@ -509,19 +489,7 @@
     }
 
    /* Do post process to get bounding boxes */
-    R_Post_Proc(drpai_output_buf);
-    
-    /* Postprocess time end */
-    auto t5 = std::chrono::high_resolution_clock::now();
-    
-    auto r_post_proc_time = std::chrono::duration_cast<std::chrono::microseconds>(t5 - t4).count();
-    auto pre_proc_time = std::chrono::duration_cast<std::chrono::microseconds>(t1 - t0).count();
-
-    POST_PROC_TIME = r_post_proc_time/1000.0;
-    PRE_PROC_TIME = pre_proc_time/1000.0;
-    INF_TIME = inf_duration/1000.0;
-    float total_time = float(inf_duration/1000.0) + float(POST_PROC_TIME) + float(pre_proc_time/1000.0);
-    TOTAL_TIME = total_time;
+    R_Post_Proc(drpai_output_buf);    
     return 0;
 }
 
@@ -546,9 +514,6 @@
     string str = "";
     int32_t ret = 0;
     int32_t baseline = 10;
-    uint8_t * img_buffer0;
-
-    img_buffer0 = (unsigned char*) (malloc(DISP_OUTPUT_WIDTH*DISP_OUTPUT_HEIGHT*BGRA_CHANNEL));
     /* Capture stream of frames from camera using Gstreamer pipeline */
     cap.open(gstreamer_pipeline, CAP_GSTREAMER);
     if (!cap.isOpened())
@@ -559,7 +524,6 @@
     while (true)
     {
         cap >> g_frame;
-        cv::Mat output_image(DISP_OUTPUT_HEIGHT,DISP_OUTPUT_WIDTH , CV_8UC3, cv::Scalar(0, 0, 0));
         fps = cap.get(CAP_PROP_FPS);
         ret = sem_getvalue(&terminate_req_sem, &inf_sem_check);
         if (0 != ret)
@@ -590,85 +554,40 @@
             draw_bounding_box();
             /*Display frame */
             stream.str("");
-            stream << "Camera Frame Rate : "<<fps <<" fps ";
-            str = stream.str();
-            Size camera_rate_size = getTextSize(str, FONT_HERSHEY_SIMPLEX,CHAR_SCALE_SMALL, HC_CHAR_THICKNESS, &baseline);
-            putText(output_image, str,Point((DISP_OUTPUT_WIDTH - camera_rate_size.width - RIGHT_ALIGN_OFFSET), (FPS_STR_Y + camera_rate_size.height)), FONT_HERSHEY_SIMPLEX, 
-                        CHAR_SCALE_SMALL, Scalar(0, 0, 0), 1.5*HC_CHAR_THICKNESS);
-            putText(output_image, str,Point((DISP_OUTPUT_WIDTH - camera_rate_size.width - RIGHT_ALIGN_OFFSET), (FPS_STR_Y + camera_rate_size.height)), FONT_HERSHEY_SIMPLEX, 
-                        CHAR_SCALE_SMALL, Scalar(255, 255, 255), HC_CHAR_THICKNESS);
-
-            stream.str("");
             stream << "Head Count: " << HEAD_COUNT;
             str = stream.str();
-            Size count_size = getTextSize(str, FONT_HERSHEY_SIMPLEX,CHAR_SCALE_LARGE, HC_CHAR_THICKNESS, &baseline);
-            putText(output_image, str,Point((DISP_OUTPUT_WIDTH - count_size.width - RIGHT_ALIGN_OFFSET), (HEAD_COUNT_STR_Y + count_size.height)), FONT_HERSHEY_SIMPLEX, 
+            putText(g_frame, str,Point(HEAD_COUNT_STR_X, HEAD_COUNT_STR_Y), FONT_HERSHEY_SIMPLEX, 
                         CHAR_SCALE_LARGE, Scalar(0, 0, 0), 1.5*HC_CHAR_THICKNESS);
-            putText(output_image, str,Point((DISP_OUTPUT_WIDTH - count_size.width - RIGHT_ALIGN_OFFSET), (HEAD_COUNT_STR_Y + count_size.height)), FONT_HERSHEY_SIMPLEX, 
+            putText(g_frame, str,Point(HEAD_COUNT_STR_X, HEAD_COUNT_STR_Y), FONT_HERSHEY_SIMPLEX, 
                         CHAR_SCALE_LARGE, Scalar(255, 255, 255), HC_CHAR_THICKNESS);
 
-            stream.str("");
-            stream << "Total Time: "<< fixed <<setprecision(1) << TOTAL_TIME<<" ms";
-            str = stream.str();
-            Size tot_time_size = getTextSize(str, FONT_HERSHEY_SIMPLEX,CHAR_SCALE_LARGE, HC_CHAR_THICKNESS, &baseline);
-            putText(output_image, str,Point((DISP_OUTPUT_WIDTH - tot_time_size.width - RIGHT_ALIGN_OFFSET), (T_TIME_STR_Y + tot_time_size.height)), FONT_HERSHEY_SIMPLEX, 
-                        CHAR_SCALE_LARGE, Scalar(0, 0, 0), 1.5*HC_CHAR_THICKNESS);
-            putText(output_image, str,Point((DISP_OUTPUT_WIDTH - tot_time_size.width - RIGHT_ALIGN_OFFSET), (T_TIME_STR_Y + tot_time_size.height)), FONT_HERSHEY_SIMPLEX, 
-                        CHAR_SCALE_LARGE, Scalar(0, 255, 0), HC_CHAR_THICKNESS);
-            stream.str("");
-            stream << "Pre-Proc: "<< fixed <<setprecision(1) << PRE_PROC_TIME<<" ms";
-            str = stream.str();
-            Size pre_proc_size = getTextSize(str, FONT_HERSHEY_SIMPLEX,CHAR_SCALE_SMALL, HC_CHAR_THICKNESS, &baseline);
-            putText(output_image, str,Point((DISP_OUTPUT_WIDTH - pre_proc_size.width - RIGHT_ALIGN_OFFSET), (PRE_TIME_STR_Y + pre_proc_size.height)), FONT_HERSHEY_SIMPLEX, 
-                        CHAR_SCALE_SMALL, Scalar(0, 0, 0), 1.5*HC_CHAR_THICKNESS);
-            putText(output_image, str,Point((DISP_OUTPUT_WIDTH - pre_proc_size.width - RIGHT_ALIGN_OFFSET), (PRE_TIME_STR_Y + pre_proc_size.height)), FONT_HERSHEY_SIMPLEX, 
-                        CHAR_SCALE_SMALL, Scalar(255, 255, 255), HC_CHAR_THICKNESS);
-            stream.str("");
-            stream << "Inference: "<< fixed <<setprecision(1) << INF_TIME<<" ms";
-            str = stream.str();
-            Size inf_size = getTextSize(str, FONT_HERSHEY_SIMPLEX,CHAR_SCALE_SMALL, HC_CHAR_THICKNESS, &baseline);
-            putText(output_image, str,Point((DISP_OUTPUT_WIDTH - inf_size.width - RIGHT_ALIGN_OFFSET), (I_TIME_STR_Y + inf_size.height)), FONT_HERSHEY_SIMPLEX, 
-                        CHAR_SCALE_SMALL, Scalar(0, 0, 0), 1.5*HC_CHAR_THICKNESS);
-            putText(output_image, str,Point((DISP_OUTPUT_WIDTH - inf_size.width - RIGHT_ALIGN_OFFSET), (I_TIME_STR_Y + inf_size.height)), FONT_HERSHEY_SIMPLEX, 
-                        CHAR_SCALE_SMALL, Scalar(255, 255, 255), HC_CHAR_THICKNESS);
-            stream.str("");
-            stream << "Post-Proc: "<< fixed <<setprecision(1) << POST_PROC_TIME<<" ms";
-            str = stream.str();
-            Size post_proc_size = getTextSize(str, FONT_HERSHEY_SIMPLEX,CHAR_SCALE_SMALL, HC_CHAR_THICKNESS, &baseline);
-            putText(output_image, str,Point((DISP_OUTPUT_WIDTH - post_proc_size.width - RIGHT_ALIGN_OFFSET), (P_TIME_STR_Y + post_proc_size.height)), FONT_HERSHEY_SIMPLEX, 
-                        CHAR_SCALE_SMALL, Scalar(0, 0, 0), 1.5*HC_CHAR_THICKNESS);
-            putText(output_image, str,Point((DISP_OUTPUT_WIDTH - post_proc_size.width - RIGHT_ALIGN_OFFSET), (P_TIME_STR_Y + post_proc_size.height)), FONT_HERSHEY_SIMPLEX, 
-                        CHAR_SCALE_SMALL, Scalar(255, 255, 255), HC_CHAR_THICKNESS);
-            
             Size size(DISP_INF_WIDTH, DISP_INF_HEIGHT);
             /*resize the image to the keep ratio size*/
-            resize(g_frame, g_frame, size);            
-            g_frame.copyTo(output_image(Rect(0, 60, DISP_INF_WIDTH, DISP_INF_HEIGHT)));
-            namedWindow("Output Image", WND_PROP_FULLSCREEN);
-            setWindowProperty("Output Image", WND_PROP_FULLSCREEN, WINDOW_FULLSCREEN);
+            resize(g_frame, g_frame, size);   
+            /* Display the frame in a window */
+            cv::imshow("Output Image", g_frame);
+
+            char key = (char) cv::waitKey(1);
+            if (key == 'q' || key == 27) 
+            {
+                break;
+            }
             string click_req = "Output Image";
             setMouseCallback(click_req,click_event,NULL);
-            cv::Mat bgra_image;
-            cv::cvtColor(output_image, bgra_image, cv::COLOR_BGR2BGRA);
-           
-            memcpy(img_buffer0, bgra_image.data, DISP_OUTPUT_WIDTH * DISP_OUTPUT_HEIGHT * BGRA_CHANNEL);
-            wayland.commit(img_buffer0, NULL);
-        }
-    }
-    free(img_buffer0);
+            
+        }
+    }
     
     cap.release(); 
     destroyAllWindows();
     err:
     /*Set Termination Request Semaphore to 0*/
-    free(img_buffer0);
     sem_trywait(&terminate_req_sem);
     goto ai_inf_end;
     /*AI Thread Termination*/
     ai_inf_end:
         /*To terminate the loop in Capture Thread.*/
         printf("AI Inference Thread Terminated\n");
-        free(img_buffer0);
         pthread_exit(NULL);
         return;
 }
@@ -831,13 +750,6 @@
 
 void *R_Inf_Thread(void *threadid)
 {
-    int8_t ret = 0;
-    ret = wayland.init(DISP_OUTPUT_WIDTH, DISP_OUTPUT_HEIGHT, BGRA_CHANNEL);
-    if(0 != ret)
-    {
-        fprintf(stderr, "[ERROR] Failed to initialize Image for Wayland\n");
-        goto err;
-    }
     capture_frame(gstreamer_pipeline);
 
 /*Error Processing*/
@@ -912,11 +824,11 @@
     }
     OCA_Activate( &OCA_list[0] );
 
-    if (strcmp(argv[1],"USB")==0)
+    if (strcmp(argv[1],"USB")==0 || strcmp(argv[1],"IMAGE")==0)
     {   
-        if (argc >= 3 )
-        {
-            drpai_freq = atoi(argv[2]);
+        if (argc >= 4 )
+        {
+            drpai_freq = atoi(argv[3]);
             if ((1 <= drpai_freq) && (127 >= drpai_freq))
             {
                 printf("Argument : <AI-MAC_freq_factor> = %d\n", drpai_freq);
@@ -976,9 +888,35 @@
  
     std::cout << "[INFO] loaded runtime model :" << model_dir << "\n\n";
     switch (input_source_map[input_source])
-    { 
+    {
+        /* Input Source : IMAGE*/
+        case 1:
+        {
+            std::cout << "Image_path: " << argv[2] << std::endl;
+            // read frame
+            g_frame = imread(argv[2]);
+
+            /* If empty frame */
+            if (g_frame.empty())
+            {
+                std::cout << "Failed to load image!" << std::endl;
+                return -1;
+            }
+            resize(g_frame, g_frame, Size(IMAGE_WIDTH, IMAGE_HEIGHT));
+            int ret = Head_Detection();
+
+            if (ret != 0)
+            {
+                fprintf(stderr, "[Error] Inference Not working !!! ");
+                return -1;
+            }
+            draw_bounding_box();
+            imwrite("Output_Image.png", g_frame);
+        }
+        break;
+
         /* Input Source : USB*/
-        case 1:{
+        case 2:{
             std::cout << "[INFO] USB CAMERA \n";
             media_port = query_device_status("usb");
             gstreamer_pipeline = "v4l2src device=" + media_port + " ! video/x-raw, width=640, height=480 ! videoconvert ! appsink";
@@ -1044,7 +982,6 @@
         sem_destroy(&terminate_req_sem);
     }
     /* Exit the program */
-    wayland.exit();
     close(drpai_fd);
     return 0;
 

