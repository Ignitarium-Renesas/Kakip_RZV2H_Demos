diff --git a/07_Animal_detection/src/animal_detection.cpp b/07_Animal_detection/src/animal_detection.cpp
index 5660132..57c668c 100644
--- a/07_Animal_detection/src/animal_detection.cpp
+++ b/07_Animal_detection/src/animal_detection.cpp
@@ -39,8 +39,6 @@
 #include <linux/input.h>
 #include <builtin_fp16.h>
 #include <opencv2/opencv.hpp>
-#include "wayland.h"
-
 
 using namespace std;
 using namespace cv;
@@ -50,7 +48,6 @@ MeraDrpRuntimeWrapper runtime;
 
 /*Global Variables*/
 static float drpai_output_buf[INF_OUT_SIZE];
-static Wayland wayland;
 static pthread_t ai_inf_thread;
 static pthread_t kbhit_thread;
 static sem_t terminate_req_sem;
@@ -68,11 +65,13 @@ uint64_t drpaimem_addr_start = 0;
 bool runtime_status = false; 
 static vector<detection> det;
 
-float fps = 0;
+int32_t ANIMAL_COUNT= 0;
 float TOTAL_TIME = 0;
 float INF_TIME= 0;
 float POST_PROC_TIME = 0;
 float PRE_PROC_TIME = 0;
+int frame_count = 0;  
+float accumulated_time = 0.0f;
 
 /*Global frame */
 Mat g_frame;
@@ -81,8 +80,9 @@ VideoCapture cap;
 cv::Mat output_image;
 
 /* Map to store input source list */
-std::map<std::string, int> input_source_map ={    
-    {"USB", 1}
+std::map<std::string, int> input_source_map ={  
+    {"IMAGE", 1},   
+    {"USB", 2}
      } ;
 
 /*****************************************
@@ -384,12 +384,16 @@ void draw_bounding_box(void)
         Point textleft(x_min,y_min+CLASS_LABEL_HEIGHT);
         Point textright(x_min+CLASS_LABEL_WIDTH,y_min);
 
+        std::cout<<"topleft :"<<topLeft<<endl;
+        std::cout<<"bottomRight :"<<bottomRight<<endl;
+
         rectangle(g_frame, topLeft, bottomRight, Scalar(0, 0, 0), BOX_THICKNESS);
         rectangle(g_frame, topLeft2, bottomRight2, Scalar(255, 255, 255), BOX_THICKNESS);
         /*solid rectangle over class name */
         rectangle(g_frame, textleft, textright, Scalar(59, 94, 53), -1);
         putText(g_frame, result_str, textleft, FONT_HERSHEY_SIMPLEX, CHAR_SCALE_XS, Scalar(255, 255, 255), BOX_CHAR_THICKNESS);            
     }
+    ANIMAL_COUNT = result_cnt++;
     return;
 }
 
@@ -523,6 +527,15 @@ int Animal_Detection()
     return 0;
 }
 
+void click_event(int event, int x, int y, int flags, void* userdata)
+{
+    if (event == EVENT_LBUTTONDBLCLK)
+    {
+        std::cout<<"Exiting the event "<<std::endl;
+        exit(0);
+    }
+}
+
 /*****************************************
  * Function Name : capture_frame
  * Description   : function to open camera gstreamer pipeline.
@@ -534,11 +547,8 @@ void capture_frame(std::string gstreamer_pipeline )
     int32_t inf_sem_check = 0;
     string str = "";
     int32_t ret = 0;
-    int32_t baseline = 10;
-    uint8_t * img_buffer0;
-
-    img_buffer0 = (unsigned char*) (malloc(DISP_OUTPUT_WIDTH*DISP_OUTPUT_HEIGHT*BGRA_CHANNEL));
-    
+    int32_t baseline = 10; 
+    float fps = 0.0f;   
     /* Capture stream of frames from camera using Gstreamer pipeline */
     cap.open(gstreamer_pipeline, CAP_GSTREAMER);
     if (!cap.isOpened())
@@ -553,8 +563,6 @@ void capture_frame(std::string gstreamer_pipeline )
         string result_str;
         int32_t result_cnt =0;
         cap >> g_frame;
-        cv::Mat output_image(DISP_OUTPUT_HEIGHT,DISP_OUTPUT_WIDTH , CV_8UC3, cv::Scalar(0, 0, 0));
-        double fps = cap.get(CAP_PROP_FPS);
         ret = sem_getvalue(&terminate_req_sem, &inf_sem_check);
         if (0 != ret)
         {
@@ -580,51 +588,18 @@ void capture_frame(std::string gstreamer_pipeline )
                 std::cerr << "[ERROR] Inference Not working !!! " << std::endl;
             }
 
+            accumulated_time += TOTAL_TIME;
+            frame_count++;
+            if (frame_count == 30) {
+            float avg_time_per_frame = accumulated_time / 30.0f;  
+            fps = 1000.0f / avg_time_per_frame;  
+            // Reset counters
+            frame_count = 0;
+            accumulated_time = 0.0f;
+            }
+
             /* Draw bounding box on the frame */
             draw_bounding_box();
-            /*Display frame */
-            stream.str("");
-            stream << "Camera Frame Rate: "<<fps<<" fps ";
-            str = stream.str();
-            Size camera_rate_size = getTextSize(str, FONT_HERSHEY_SIMPLEX,CHAR_SCALE_SMALL, HC_CHAR_THICKNESS, &baseline);
-            putText(output_image, str,Point((DISP_OUTPUT_WIDTH - camera_rate_size.width + FRAME_OFFSET), (FPS_STR_Y + camera_rate_size.height)), FONT_HERSHEY_SIMPLEX, 
-                        CHAR_SCALE_SMALL, Scalar(0, 0, 0), 1.5*HC_CHAR_THICKNESS);
-            putText(output_image, str,Point((DISP_OUTPUT_WIDTH - camera_rate_size.width - FRAME_OFFSET), (FPS_STR_Y + camera_rate_size.height)), FONT_HERSHEY_SIMPLEX, 
-                        CHAR_SCALE_SMALL, Scalar(255, 255, 255), HC_CHAR_THICKNESS);
-
-            stream.str("");
-            stream <<"Total Time: " << fixed <<setprecision(1)<< TOTAL_TIME<<" ms";
-            str = stream.str();
-            Size tot_time_size = getTextSize(str, FONT_HERSHEY_SIMPLEX,CHAR_SCALE_LARGE, HC_CHAR_THICKNESS, &baseline);
-            putText(output_image, str,Point((DISP_OUTPUT_WIDTH - tot_time_size.width - RIGHT_ALIGN_OFFSET), (T_TIME_STR_Y + tot_time_size.height)), FONT_HERSHEY_SIMPLEX, 
-                        CHAR_SCALE_LARGE, Scalar(0, 0, 0), 1.5*HC_CHAR_THICKNESS);
-            putText(output_image, str,Point((DISP_OUTPUT_WIDTH - tot_time_size.width - RIGHT_ALIGN_OFFSET), (T_TIME_STR_Y + tot_time_size.height)), FONT_HERSHEY_SIMPLEX, 
-                        CHAR_SCALE_LARGE, Scalar(0, 255, 0), HC_CHAR_THICKNESS);
-            stream.str("");
-            stream << "Pre-Proc: " <<fixed <<setprecision(1)<< PRE_PROC_TIME<<" ms";
-            str = stream.str();
-            Size pre_proc_size = getTextSize(str, FONT_HERSHEY_SIMPLEX,CHAR_SCALE_SMALL, HC_CHAR_THICKNESS, &baseline);
-            putText(output_image, str,Point((DISP_OUTPUT_WIDTH - pre_proc_size.width - RIGHT_ALIGN_OFFSET), (PRE_TIME_STR_Y + pre_proc_size.height)), FONT_HERSHEY_SIMPLEX, 
-                        CHAR_SCALE_SMALL, Scalar(0, 0, 0), 1.5*HC_CHAR_THICKNESS);
-            putText(output_image, str,Point((DISP_OUTPUT_WIDTH - pre_proc_size.width - RIGHT_ALIGN_OFFSET), (PRE_TIME_STR_Y + pre_proc_size.height)), FONT_HERSHEY_SIMPLEX, 
-                        CHAR_SCALE_SMALL, Scalar(255, 255, 255), HC_CHAR_THICKNESS);
-            stream.str("");
-            stream << "Inference: " << fixed <<setprecision(1)<< INF_TIME<<" ms";
-            str = stream.str();
-            Size inf_size = getTextSize(str, FONT_HERSHEY_SIMPLEX,CHAR_SCALE_SMALL, HC_CHAR_THICKNESS, &baseline);
-            putText(output_image, str,Point((DISP_OUTPUT_WIDTH - inf_size.width - RIGHT_ALIGN_OFFSET), (I_TIME_STR_Y + inf_size.height)), FONT_HERSHEY_SIMPLEX, 
-                        CHAR_SCALE_SMALL, Scalar(0, 0, 0), 1.5*HC_CHAR_THICKNESS);
-            putText(output_image, str,Point((DISP_OUTPUT_WIDTH - inf_size.width - RIGHT_ALIGN_OFFSET), (I_TIME_STR_Y + inf_size.height)), FONT_HERSHEY_SIMPLEX, 
-                        CHAR_SCALE_SMALL, Scalar(255, 255, 255), HC_CHAR_THICKNESS);
-            stream.str("");
-            stream << "Post-Proc: " <<fixed <<setprecision(1)<< POST_PROC_TIME<<" ms";
-            str = stream.str();
-            Size post_proc_size = getTextSize(str, FONT_HERSHEY_SIMPLEX,CHAR_SCALE_SMALL, HC_CHAR_THICKNESS, &baseline);
-            putText(output_image, str,Point((DISP_OUTPUT_WIDTH - post_proc_size.width - RIGHT_ALIGN_OFFSET), (P_TIME_STR_Y + post_proc_size.height)), FONT_HERSHEY_SIMPLEX, 
-                        CHAR_SCALE_SMALL, Scalar(0, 0, 0), 1.5*HC_CHAR_THICKNESS);
-            putText(output_image, str,Point((DISP_OUTPUT_WIDTH - post_proc_size.width - RIGHT_ALIGN_OFFSET), (P_TIME_STR_Y + post_proc_size.height)), FONT_HERSHEY_SIMPLEX, 
-                        CHAR_SCALE_SMALL, Scalar(255, 255, 255), HC_CHAR_THICKNESS);
-
             for (i = 0; i < det.size(); i++)
             {
                 /* Skip the overlapped bounding boxes */
@@ -641,38 +616,39 @@ void capture_frame(std::string gstreamer_pipeline )
                 stream.str("");
                 stream << "Class: " << label_file_map[det[i].c].c_str() << " " << fixed << setprecision(2)<< (det[i].prob*100)<<"%";
                 str = stream.str();
-                Size count_size = getTextSize(str, FONT_HERSHEY_SIMPLEX,CHAR_SCALE_SMALL, HC_CHAR_THICKNESS, &baseline);
-                putText(output_image, str,Point((DISP_OUTPUT_WIDTH - count_size.width - RIGHT_ALIGN_OFFSET), (LABEL_STR_Y +offset*(result_cnt -1)+ count_size.height)), FONT_HERSHEY_SIMPLEX, 
+                putText(g_frame, str,Point(30,30), FONT_HERSHEY_SIMPLEX, 
                             CHAR_SCALE_SMALL, Scalar(0, 255, 255), CLASS_CHAR_THICKNESS);
             }
-
+            stream.str("");
+            stream << "FPS: " << fixed << setprecision(2)<< fps;
+            str = stream.str();
+            putText(g_frame, str,Point(FPS_STR_X, FPS_STR_Y), FONT_HERSHEY_SIMPLEX, CHAR_SCALE_SMALL, Scalar(255, 255, 255), CLASS_CHAR_THICKNESS);
             Size size(DISP_INF_WIDTH, DISP_INF_HEIGHT);
             /*resize the image to the keep ratio size*/
-            resize(g_frame, g_frame, size);            
-            g_frame.copyTo(output_image(Rect(0, 60, DISP_INF_WIDTH, DISP_INF_HEIGHT)));
-            namedWindow("Output Image", WND_PROP_FULLSCREEN);
-            setWindowProperty("Output Image", WND_PROP_FULLSCREEN, WINDOW_FULLSCREEN);
-            cv::Mat bgra_image;
-            cv::cvtColor(output_image, bgra_image, cv::COLOR_BGR2BGRA);
-           
-            memcpy(img_buffer0, bgra_image.data, DISP_OUTPUT_WIDTH * DISP_OUTPUT_HEIGHT * BGRA_CHANNEL);
-            wayland.commit(img_buffer0, NULL);
+            resize(g_frame, g_frame, size);   
+            /* Display the frame in a window */
+            cv::imshow("Output Image", g_frame);
+
+            char key = (char) cv::waitKey(1);
+            if (key == 'q' || key == 27) 
+            {
+                break;
+            }
+            string click_req = "Output Image";
+            setMouseCallback(click_req,click_event,NULL);         
+            
         }
     }
-    free(img_buffer0);
-
     cap.release(); 
     destroyAllWindows();
 err:
     /*Set Termination Request Semaphore to 0*/
-    free(img_buffer0);
     sem_trywait(&terminate_req_sem);
     goto ai_inf_end;
     /*AI Thread Termination*/
     ai_inf_end:
         /*To terminate the loop in Capture Thread.*/
         printf("AI Inference Thread Terminated\n");
-        free(img_buffer0);
         pthread_exit(NULL);
     return;
 }
@@ -837,13 +813,7 @@ std::string query_device_status(std::string device_type)
 
 void *R_Inf_Thread(void *threadid)
 {
-    int8_t ret = 0;
-    ret = wayland.init(DISP_OUTPUT_WIDTH, DISP_OUTPUT_HEIGHT, BGRA_CHANNEL);
-    if(0 != ret)
-    {
-        fprintf(stderr, "[ERROR] Failed to initialize Image for Wayland\n");
-        goto err;
-    }
+    
     capture_frame(gstreamer_pipeline);
 
 /*Error Processing*/
@@ -917,11 +887,11 @@ int main(int argc, char *argv[])
     }
     OCA_Activate( &OCA_list[0] );
 
-    if (strcmp(argv[1],"USB")==0)
+    if (strcmp(argv[1],"USB")==0 || strcmp(argv[1],"IMAGE")==0)
     {   
-        if (argc >= 3 )
+        if (argc >= 4 )
         {
-            drpai_freq = atoi(argv[2]);
+            drpai_freq = atoi(argv[3]);
             if ((1 <= drpai_freq) && (127 >= drpai_freq))
             {
                 printf("Argument : <AI-MAC_freq_factor> = %d\n", drpai_freq);
@@ -984,8 +954,34 @@ int main(int argc, char *argv[])
     std::cout << "[INFO] loaded runtime model :" << model_dir << "\n\n";
         switch (input_source_map[input_source])
     {
+        /* Input Source : IMAGE*/
+        case 1:
+        {
+            std::cout << "Image_path: " << argv[2] << std::endl;
+            // read frame
+            g_frame = imread(argv[2]);
+
+            /* If empty frame */
+            if (g_frame.empty())
+            {
+                std::cout << "Failed to load image!" << std::endl;
+                return -1;
+            }
+            resize(g_frame, g_frame, Size(IMAGE_WIDTH, IMAGE_HEIGHT));
+            int ret = Animal_Detection();
+
+            if (ret != 0)
+            {
+                fprintf(stderr, "[Error] Inference Not working !!! ");
+                return -1;
+            }
+            draw_bounding_box();
+            imwrite("Output_Image.png", g_frame);
+        }
+        break;
+
         /* Input Source : USB*/
-        case 1:{
+        case 2:{
             std::cout << "[INFO] USB CAMERA \n";
             media_port = query_device_status("usb");
             gstreamer_pipeline = "v4l2src device=" + media_port + " ! video/x-raw, width=640, height=480 ! videoconvert ! appsink";
@@ -1051,7 +1047,6 @@ end_threads:
         sem_destroy(&terminate_req_sem);
     }
     /* Exit the program */
-    wayland.exit();
     close(drpai_fd);
     return 0;
 
diff --git a/07_Animal_detection/src/define.h b/07_Animal_detection/src/define.h
index da27b7a..f34f252 100644
--- a/07_Animal_detection/src/define.h
+++ b/07_Animal_detection/src/define.h
@@ -125,21 +125,10 @@ const static double anchors[] =
 #define DISP_RESIZE_HEIGHT           (1080)
 
 /*Image:: Text information to be drawn on image*/
-
-#define ANIMAL_STR_X                (645)
-#define ANIMAL_STR_Y                (30)
-#define FPS_STR_X                   (645)
-#define FPS_STR_Y                   (360)
-#define PRE_TIME_STR_X              (645)
-#define PRE_TIME_STR_Y              (170)
-#define P_TIME_STR_X                (645)
-#define P_TIME_STR_Y                (270)
-#define I_TIME_STR_X                (645)
-#define I_TIME_STR_Y                (220)
-#define T_TIME_STR_X                (645)
-#define T_TIME_STR_Y                (120)
 #define LABEL_STR_X                 (645)
 #define LABEL_STR_Y                 (420)
+#define FPS_STR_X                   (80)
+#define FPS_STR_Y                   (80)
 #define CHAR_SCALE_LARGE            (1.6)
 #define CHAR_SCALE_SMALL            (1.2)
 #define CHAR_SCALE_XS               (0.5)
